#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <assert.h>
#include <unistd.h>
#include <pthread.h>
#include "core/model_manager.h"
#include "core/tensor.h"
#include "core/memory_pool.h"
#include "utils/logger.h"
#include "pipeline/pipeline_manager.h"

/**
 * @brief Modyn é›†æˆæµ‹è¯•
 * 
 * æµ‹è¯•æ•´ä¸ªç³»ç»Ÿçš„ç«¯åˆ°ç«¯åŠŸèƒ½
 */

// æµ‹è¯•å®Œæ•´çš„æ¨ç†æµç¨‹
void test_end_to_end_inference(void) {
    printf("æµ‹è¯•ç«¯åˆ°ç«¯æ¨ç†æµç¨‹...\n");
    
    // 1. åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
    ModelManager* manager = model_manager_create();
    assert(manager != NULL);
    
    // 2. é…ç½®æ¨¡å‹
    ModelConfig config = {0};
    config.model_path = "test_model.dummy";
    config.model_id = "integration_test_model";
    config.version = "1.0.0";
    config.backend = INFER_BACKEND_DUMMY;
    config.max_instances = 1;
    config.enable_cache = true;
    
    // 3. åŠ è½½æ¨¡å‹
    ModelHandle model = model_manager_load(manager, config.model_path, &config);
    assert(model != NULL);
    
    // 4. åˆ›å»ºè¾“å…¥å¼ é‡
    uint32_t input_dims[] = {1, 3, 224, 224};
    TensorShape input_shape = tensor_shape_create(input_dims, 4);
    Tensor input_tensor = tensor_create("test_input", TENSOR_TYPE_FLOAT32, &input_shape, TENSOR_FORMAT_NCHW);
    
    // åˆ†é…å¹¶å¡«å……è¾“å…¥æ•°æ®
    input_tensor.data = malloc(input_tensor.size);
    input_tensor.owns_data = true;
    assert(input_tensor.data != NULL);
    
    float* input_data = (float*)input_tensor.data;
    uint32_t element_count = tensor_get_element_count(&input_tensor);
    for (uint32_t i = 0; i < element_count; i++) {
        input_data[i] = (float)(i % 256) / 255.0f;  // æ¨¡æ‹Ÿå›¾åƒæ•°æ®
    }
    
    // 5. åˆ›å»ºè¾“å‡ºå¼ é‡
    uint32_t output_dims[] = {1, 1000};
    TensorShape output_shape = tensor_shape_create(output_dims, 2);
    Tensor output_tensor = tensor_create("test_output", TENSOR_TYPE_FLOAT32, &output_shape, TENSOR_FORMAT_NC);
    
    output_tensor.data = malloc(output_tensor.size);
    output_tensor.owns_data = true;
    assert(output_tensor.data != NULL);
    
    // 6. æ‰§è¡Œæ¨ç†
    int ret = model_infer_simple(model, &input_tensor, &output_tensor);
    assert(ret == 0);
    
    // 7. éªŒè¯è¾“å‡º
    float* output_data = (float*)output_tensor.data;
    assert(output_data != NULL);
    
    // æ£€æŸ¥è¾“å‡ºæ•°æ®æ˜¯å¦åˆç†
    bool has_valid_data = false;
    for (int i = 0; i < 1000; i++) {
        if (output_data[i] > 0.0f && output_data[i] <= 1.0f) {
            has_valid_data = true;
            break;
        }
    }
    assert(has_valid_data);
    
    // 8. è·å–æ¨¡å‹ä¿¡æ¯
    ModelInfo info;
    ret = model_manager_get_info(manager, config.model_id, &info);
    assert(ret == 0);
    assert(info.inference_count >= 1);
    
    // 9. æ¸…ç†èµ„æº
    tensor_free(&input_tensor);
    tensor_free(&output_tensor);
    free(info.model_id);
    free(info.version);
    
    model_manager_unload(manager, model);
    model_manager_destroy(manager);
    
    printf("âœ… ç«¯åˆ°ç«¯æ¨ç†æµç¨‹æµ‹è¯•é€šè¿‡\n");
}

// æµ‹è¯•å†…å­˜æ± ä¸å¼ é‡çš„é›†æˆ
void test_memory_pool_tensor_integration(void) {
    printf("æµ‹è¯•å†…å­˜æ± ä¸å¼ é‡é›†æˆ...\n");
    
    // åˆ›å»ºå†…å­˜æ± 
    memory_pool_config_t config = {
        .type = MEMORY_POOL_CPU,
        .initial_size = 1024 * 1024,  // 1MB
        .max_size = 1024 * 1024 * 10, // 10MB
        .grow_size = 1024 * 1024,     // 1MB
        .alignment = 32,
        .strategy = MEMORY_ALLOC_BEST_FIT,
        .enable_tracking = true,
        .enable_debug = false,
        .external_memory = NULL,
        .external_size = 0
    };
    
    memory_pool_t pool = memory_pool_create(&config);
    assert(pool != NULL);
    
    // è®¡ç®—å¼ é‡å¤§å°
    uint32_t dims[] = {1, 3, 224, 224};
    tensor_shape_t shape = tensor_shape_create(dims, 4);
    tensor_t tensor = tensor_create("test", TENSOR_TYPE_FLOAT32, &shape, TENSOR_FORMAT_NHWC);
    size_t element_count = tensor_get_element_count(&tensor);
    size_t tensor_size = element_count * sizeof(float);
    
    // ä½¿ç”¨å†…å­˜æ± åˆ†é…å¼ é‡æ•°æ®
    memory_handle_t handle = memory_pool_alloc(pool, tensor_size, 8, "tensor_data");
    assert(handle != NULL);
    void* data = memory_handle_get_ptr(handle);
    assert(data != NULL);
    assert(memory_handle_get_size(handle) >= tensor_size);
    
    // å°†å†…å­˜æ± åˆ†é…çš„å†…å­˜èµ‹å€¼ç»™å¼ é‡
    tensor.data = data;
    tensor.owns_data = false;  // ç”±å†…å­˜æ± ç®¡ç†
    
    // å¡«å……æµ‹è¯•æ•°æ®
    float* float_data = (float*)data;
    for (size_t i = 0; i < element_count; i++) {
        float_data[i] = (float)i / element_count;
    }
    
    // éªŒè¯å¼ é‡æ•°æ®
    assert(tensor.data != NULL);
    assert(tensor.dtype == TENSOR_TYPE_FLOAT32);
    assert(tensor.shape.dims[0] == 1);
    assert(tensor.shape.dims[1] == 3);
    assert(tensor.shape.dims[2] == 224);
    assert(tensor.shape.dims[3] == 224);
    
    // é‡Šæ”¾å†…å­˜
    memory_pool_free(pool, handle);
    memory_pool_destroy(pool);
    printf("âœ… å†…å­˜æ± ä¸å¼ é‡é›†æˆæµ‹è¯•é€šè¿‡\n");
}

// æµ‹è¯•å¤šçº¿ç¨‹æ¨ç†
typedef struct {
    ModelManager* manager;
    ModelHandle model;
    int thread_id;
    int iterations;
    int success_count;
} ThreadInferData;

void* thread_infer_func(void* arg) {
    ThreadInferData* data = (ThreadInferData*)arg;
    
    for (int i = 0; i < data->iterations; i++) {
        // åˆ›å»ºè¾“å…¥å¼ é‡
        uint32_t dims[] = {1, 3, 32, 32};  // å°å°ºå¯¸åŠ å¿«æµ‹è¯•
        TensorShape shape = tensor_shape_create(dims, 4);
        Tensor input = tensor_create("thread_input", TENSOR_TYPE_FLOAT32, &shape, TENSOR_FORMAT_NCHW);
        
        input.data = malloc(input.size);
        input.owns_data = true;
        if (!input.data) continue;
        
        // å¡«å……è¾“å…¥æ•°æ®
        float* input_data = (float*)input.data;
        for (uint32_t j = 0; j < tensor_get_element_count(&input); j++) {
            input_data[j] = (float)(data->thread_id * 1000 + j) / 10000.0f;
        }
        
        // åˆ›å»ºè¾“å‡ºå¼ é‡
        uint32_t output_dims[] = {1, 10};
        TensorShape output_shape = tensor_shape_create(output_dims, 2);
        Tensor output = tensor_create("thread_output", TENSOR_TYPE_FLOAT32, &output_shape, TENSOR_FORMAT_NC);
        
        output.data = malloc(output.size);
        output.owns_data = true;
        if (!output.data) {
            tensor_free(&input);
            continue;
        }
        
        // æ‰§è¡Œæ¨ç†
        if (model_infer_simple(data->model, &input, &output) == 0) {
            data->success_count++;
        }
        
        // æ¸…ç†
        tensor_free(&input);
        tensor_free(&output);
        
        // çŸ­æš‚ä¼‘æ¯
        usleep(1000);
    }
    
    return NULL;
}

void test_multi_thread_inference(void) {
    printf("æµ‹è¯•å¤šçº¿ç¨‹æ¨ç†...\n");
    
    // åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨å’Œæ¨¡å‹
    ModelManager* manager = model_manager_create();
    assert(manager != NULL);
    
    ModelConfig config = {0};
    config.model_path = "multithread_test.dummy";
    config.model_id = "multithread_model";
    config.version = "1.0.0";
    config.backend = INFER_BACKEND_DUMMY;
    
    ModelHandle model = model_manager_load(manager, config.model_path, &config);
    assert(model != NULL);
    
    // åˆ›å»ºå¤šä¸ªçº¿ç¨‹
    const int num_threads = 4;
    const int iterations = 50;
    
    pthread_t threads[num_threads];
    ThreadInferData thread_data[num_threads];
    
    // å¯åŠ¨çº¿ç¨‹
    for (int i = 0; i < num_threads; i++) {
        thread_data[i].manager = manager;
        thread_data[i].model = model;
        thread_data[i].thread_id = i;
        thread_data[i].iterations = iterations;
        thread_data[i].success_count = 0;
        
        assert(pthread_create(&threads[i], NULL, thread_infer_func, &thread_data[i]) == 0);
    }
    
    // ç­‰å¾…çº¿ç¨‹å®Œæˆ
    for (int i = 0; i < num_threads; i++) {
        assert(pthread_join(threads[i], NULL) == 0);
    }
    
    // æ£€æŸ¥ç»“æœ
    int total_success = 0;
    for (int i = 0; i < num_threads; i++) {
        total_success += thread_data[i].success_count;
        printf("  çº¿ç¨‹ %d: %d/%d æˆåŠŸ\n", i, thread_data[i].success_count, iterations);
    }
    
    printf("  æ€»æˆåŠŸ: %d/%d\n", total_success, num_threads * iterations);
    assert(total_success > num_threads * iterations * 0.8);  // è‡³å°‘80%æˆåŠŸç‡
    
    // æ¸…ç†
    model_manager_unload(manager, model);
    model_manager_destroy(manager);
    
    printf("âœ… å¤šçº¿ç¨‹æ¨ç†æµ‹è¯•é€šè¿‡\n");
}

// æµ‹è¯•ç®¡é“ç³»ç»Ÿé›†æˆ
void test_pipeline_integration(void) {
    printf("æµ‹è¯•ç®¡é“ç³»ç»Ÿé›†æˆ...\n");
    
    // åˆ›å»ºç®¡é“ç®¡ç†å™¨
    PipelineManager pm = pipeline_manager_create();
    assert(pm != NULL);
    
    // åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
    ModelManager* mm = model_manager_create();
    assert(mm != NULL);
    
    // åŠ è½½æµ‹è¯•æ¨¡å‹
    ModelConfig config = {0};
    config.model_path = "pipeline_test.dummy";
    config.model_id = "pipeline_model";
    config.version = "1.0.0";
    config.backend = INFER_BACKEND_DUMMY;
    
    ModelHandle model = model_manager_load(mm, config.model_path, &config);
    assert(model != NULL);
    
    // åˆ›å»ºç®¡é“
    PipelineConfig pipe_config = {0};
    pipe_config.pipeline_id = "test_pipeline";
    pipe_config.exec_mode = PIPELINE_EXEC_SEQUENTIAL;
    
    Pipeline pipeline = pipeline_create(pm, &pipe_config);
    assert(pipeline != NULL);
    
    // æ·»åŠ èŠ‚ç‚¹
    PipelineNodeConfig node_config = {0};
    node_config.node_id = "model_node";
    node_config.type = PIPELINE_NODE_MODEL;
    node_config.model = model;
    node_config.input_count = 1;
    node_config.output_count = 1;
    
    PipelineNode node = pipeline_add_node(pipeline, &node_config);
    assert(node != NULL);
    
    // éªŒè¯ç®¡é“ä¿¡æ¯
    uint32_t node_count, connection_count;
    assert(pipeline_get_info(pipeline, &node_count, &connection_count) == 0);
    assert(node_count == 1);
    assert(connection_count == 0);
    
    // éªŒè¯ç®¡é“
    assert(pipeline_validate(pipeline) == 0);
    
    // æ¸…ç†
    model_manager_unload(mm, model);
    model_manager_destroy(mm);
    pipeline_manager_destroy(pm);  // è¿™ä¼šè‡ªåŠ¨é”€æ¯æ‰€æœ‰ç®¡é“
    
    printf("âœ… ç®¡é“ç³»ç»Ÿé›†æˆæµ‹è¯•é€šè¿‡\n");
}

// æµ‹è¯•èµ„æºæ¸…ç†
void test_resource_cleanup(void) {
    printf("æµ‹è¯•å†…å­˜æ± èµ„æºæ¸…ç†...\n");
    memory_pool_config_t config = {
        .type = MEMORY_POOL_CPU,
        .initial_size = 1024 * 5,  // 5KB
        .max_size = 1024 * 5,
        .grow_size = 1024,
        .alignment = 8,
        .strategy = MEMORY_ALLOC_FIRST_FIT,
        .enable_tracking = true,
        .enable_debug = false,
        .external_memory = NULL,
        .external_size = 0
    };
    memory_pool_t pool = memory_pool_create(&config);
    assert(pool != NULL);
    memory_handle_t handles[3];
    for (int i = 0; i < 3; i++) {
        handles[i] = memory_pool_alloc(pool, 512, 8, "cleanup_test");
        assert(handles[i] != NULL);
    }
    for (int i = 0; i < 3; i++) {
        assert(memory_pool_free(pool, handles[i]) == 0);
    }
    memory_pool_stats_t stats;
    assert(memory_pool_get_stats(pool, &stats) == 0);
    assert(stats.used_size == 0);
    assert(stats.free_count == 3);
    memory_pool_destroy(pool);
    printf("âœ… èµ„æºæ¸…ç†æµ‹è¯•é€šè¿‡\n");
}

// å‹åŠ›æµ‹è¯•
void test_stress_test(void) {
    printf("æµ‹è¯•ç³»ç»Ÿå‹åŠ›...\n");
    
    ModelManager* manager = model_manager_create();
    assert(manager != NULL);
    
    // å¿«é€ŸåŠ è½½å’Œå¸è½½å¤šä¸ªæ¨¡å‹
    for (int i = 0; i < 20; i++) {
        char model_path[64];
        char model_id[64];
        snprintf(model_path, sizeof(model_path), "stress_test_%d.dummy", i);
        snprintf(model_id, sizeof(model_id), "stress_model_%d", i);
        
        ModelConfig config = {0};
        config.model_path = model_path;
        config.model_id = model_id;
        config.backend = INFER_BACKEND_DUMMY;
        
        ModelHandle model = model_manager_load(manager, config.model_path, &config);
        if (model) {
            // å¿«é€Ÿæ¨ç†
            uint32_t dims[] = {1, 1, 8, 8};  // å¾ˆå°çš„å¼ é‡
            TensorShape shape = tensor_shape_create(dims, 4);
            Tensor input = tensor_create("stress_input", TENSOR_TYPE_FLOAT32, &shape, TENSOR_FORMAT_NCHW);
            Tensor output = tensor_create("stress_output", TENSOR_TYPE_FLOAT32, &shape, TENSOR_FORMAT_NCHW);
            
            input.data = calloc(1, input.size);
            output.data = calloc(1, output.size);
            input.owns_data = output.owns_data = true;
            
            if (input.data && output.data) {
                model_infer_simple(model, &input, &output);
            }
            
            tensor_free(&input);
            tensor_free(&output);
            model_manager_unload(manager, model);
        }
    }
    
    model_manager_destroy(manager);
    
    printf("âœ… ç³»ç»Ÿå‹åŠ›æµ‹è¯•é€šè¿‡\n");
}

int main(void) {
    // åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logger_init(LOG_LEVEL_INFO, NULL);
    logger_set_console_output(true);
    
    printf("=== Modyn é›†æˆæµ‹è¯• ===\n");
    printf("æµ‹è¯•æ•´ä¸ªç³»ç»Ÿçš„ç«¯åˆ°ç«¯åŠŸèƒ½...\n\n");
    
    test_end_to_end_inference();
    test_memory_pool_tensor_integration();
    test_multi_thread_inference();
    test_pipeline_integration();
    test_resource_cleanup();
    test_stress_test();
    
    printf("\nğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼\n");
    printf("âœ… ç³»ç»Ÿå„ç»„ä»¶åä½œæ­£å¸¸\n");
    printf("âœ… å¤šçº¿ç¨‹å®‰å…¨æ€§éªŒè¯é€šè¿‡\n");
    printf("âœ… èµ„æºç®¡ç†æ­£ç¡®\n");
    printf("âœ… æ€§èƒ½è¡¨ç°ç¨³å®š\n");
    
    logger_cleanup();
    return 0;
} 